# Uncertainty & Confidence in Deeplearning : Paper list

## Basic
* 1995-Cordella-A Method for Improving Classification Reliability of Multilayer Perceptrons [paper](https://ieeexplore.ieee.org/abstract/document/410358)
* 1999-Platt-Probabilistic outputs for support vector machines and comparisons to regularized likelihood methods [paper](https://www.researchgate.net/profile/John_Platt/publication/2594015_Probabilistic_Outputs_for_Support_Vector_Machines_and_Comparisons_to_Regularized_Likelihood_Methods/links/004635154cff5262d6000000.pdf)
* 2001-Zadrozny-Obtaining calibrated probability estimates from decision trees and naive Bayesian classifiers [paper](http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.29.3039&rep=rep1&type=pdf)
* 2005-Niculescu-Mizil-Predicting Good Probabilities With Supervised Learning [paper](https://arxiv.org/pdf/1401.3390.pdf)
* 2005-Niculescu-Mizil-Obtaining Calibrated Probabilities from Boosting [paper](https://www.aaai.org/Papers/Workshops/2007/WS-07-05/WS07-05-006.pdf)
* 2014-Naeini-Binary Classifier Calibration: Non-parametric approach [paper](http://github.com)
* 2014-VanderPals-Frequentism and Bayesianism: A Python-driven Primer [paper](https://arxiv.org/pdf/1411.5018.pdf)
* 2015-Naeini-Obtaining Well Calibrated Probabilities Using Bayesian Binning [paper](https://scholar.google.com/scholar?hl=ko&as_sdt=0%2C5&q=Obtaining+Well+Calibrated+Probabilities+Using+Bayesian+Binning&btnG=)

## Bayesian
* 2015-Gal-Dropout as a Bayesian approximation [paper](https://arxiv.org/pdf/1506.02157.pdf)
* 2016-Gal-Dropout as a Bayesian Approximation:Representing Model Uncertainty in Deep Learning [paper](http://www.jmlr.org/proceedings/papers/v48/gal16.pdf)
* 2016-McClure-Representing inferential uncertainty in deep neural networks through sampling [paper](https://openreview.net/forum?id=HJ1JBJ5gl&noteId=HJhI6ZALe)
* 2017-Kendall-What Uncertainties Do We Need in Bayesian Deep Learning for Computer Vision? [paper](http://papers.nips.cc/paper/7141-what-uncertainties-do-we-need)
* 2018-Ayhan-Test-time data augmentation for estimation of heteroscedastic aleatoric uncertainty in deep neural networks [paper](https://openreview.net/forum?id=rJZz-knjz)
* 2018-Hafner-Noise Contrastive Priors for Functional Uncertainty [paper](https://arxiv.org/abs/1807.09289)
* 2018-Sensoy-Evidential deep learning to quantify classification uncertainty [paper](http://papers.nips.cc/paper/7580-evidential-deep-learning-to-quantify-classification-uncertainty)
* 2019-Seo-Learning for single-shot confidence calibration in deep neural networks through stochastic inferences [paper](http://openaccess.thecvf.com/content_CVPR_2019/html/Seo_Learning_for_Single-Shot_Confidence_Calibration_in_Deep_Neural_Networks_Through_CVPR_2019_paper.html)
* 2019-Ghandeharioun-Characterizing Sources of Uncertainty to Proxy Calibration and Disambiguate Annotator and Data Bias [paper](https://arxiv.org/abs/1909.09285)
* 2019-Ahn-Uncertainty-based Continual Learning with Adaptive Regularization [paper](https://papers.nips.cc/paper/8690-uncertainty-based-continual-learning-with-adaptive-regularization)
* 2020-Joo-Being Bayesian about Categorical Probability [paper](https://arxiv.org/abs/2002.07965)
* [paper](http://github.com)


## Uncertainty
* 2017-Kahn-Uncertainty-Aware Reinforcement Learning for Collision Avoidance [paper](https://arxiv.org/pdf/1702.01182.pdf)
* 2017-Lakshminarayanan-Simple and Scalable Predictive Uncertainty Estimation using Deep Ensembles [paper](http://papers.nips.cc/paper/7219-simple-and-scalable-predictive-uncertainty-estimation-using-deep-ensembles)
* 2017-Guo-On Calibration of Modern Neural Networks [paper](https://arxiv.org/pdf/1706.04599.pdf)
* 2017-Mandelbaum-Distance-based Confidence Score for Neural Network Classifiers [paper](https://arxiv.org/abs/1709.09844)
* 2017-Pereyra-Regularizing neural networks by penalizing confident output distributions [paper](https://arxiv.org/abs/1701.06548)
* 2017-Pleiss-On Fairness and Calibration [paper](http://papers.nips.cc/paper/7151-on-fairness-and-calibration)
* 2018-Choi-Uncertainty-Aware Learning from Demonstration using Mixture Density Networks with Sampling-Free Variance Modeling [paper](https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8462978)
* 2018-Cortes-Ciriano-Deep Confidence: A Computationally Efficient Framework for Calculating Reliable Prediction Errors for Deep Neural Networks [paper](https://pubs.acs.org/doi/abs/10.1021/acs.jcim.8b00542)
* 2018-Jiang-To trust or not to trust a classifier [paper](http://papers.nips.cc/paper/7798-to-trust-or-not-to-trust-a-classifier)
* 2018-Gurau-Dropout Distillation for Efficiently Estimating Model Confidence [paper](https://arxiv.org/abs/1809.10562)
* 2018-Kuleshob-Accurate Uncertainties for Deep Learning Using Calibrated Regression [paper](https://arxiv.org/abs/1807.00263)
* 2018-Kumar-Trainable calibration measures for neural networks from kernel mean embeddings [paper](http://proceedings.mlr.press/v80/kumar18a.html)
* 2018-Liu-Generalized zero-shot learning with deep calibration network [paper](http://papers.nips.cc/paper/7471-generalized-zero-shot-learning-with-deep-calibration-network)
* 2018-Mozafari-Attended Temperature Scaling: A Practical Approach for Calibrating Deep Neural Networks [paper](https://arxiv.org/abs/1810.11586)
* 2018-Neumann-Relaxed Softmax: Efficient Confidence Auto-Calibration for Safe Pedestrian Detection [paper](https://openreview.net/forum?id=S1lG7aTnqQ)
* 2019-Hein-Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem [paper](http://openaccess.thecvf.com/content_CVPR_2019/html/Hein_Why_ReLU_Networks_Yield_High-Confidence_Predictions_Far_Away_From_the_CVPR_2019_paper.html)
* 2019-Bullock-XNet: A convolutional neural network (CNN) implementation for medical X-Ray image segmentation suitable for small datasets [paper](https://www.spiedigitallibrary.org/conference-proceedings-of-spie/10953/109531Z/XNet--a-convolutional-neural-network-CNN-implementation-for-medical/10.1117/12.2512451.short)
* 2019-Hendrycks-AugMix: A Simple Data Processing Method to Improve Robustness and Uncertainty [paper](https://arxiv.org/abs/1912.02781)
* 2019-Perterson-Human uncertainty makes classification more robust [paper](http://openaccess.thecvf.com/content_ICCV_2019/html/Peterson_Human_Uncertainty_Makes_Classification_More_Robust_ICCV_2019_paper.html)
* 2019-Neverova-Correlated Uncertainty for Learning Dense Correspondences from Noisy Labels [paper](https://papers.nips.cc/paper/8378-correlated-uncertainty-for-learning-dense-correspondences-from-noisy-labels)
* 2019-Hendrycks-Using pre-training can improve model robustness and uncertainty [paper](https://arxiv.org/abs/1901.09960)
* 2019-Ji-Bin-wise Temperature Scaling (BTS): Improvement in Confidence Calibration Performance through Simple Scaling Techniques [paper](https://arxiv.org/abs/1908.11528)
* 2019-Shrikumar-Calibration with Bias-Corrected Temperature Scaling Improves Domain Adaptation Under Label Shift in Modern Neural Networks [paper](https://arxiv.org/abs/1901.06852)
* 2019-Zhilu-Confidence Calibration for Convolutional Neural Networks Using Structured Dropout[paper](https://arxiv.org/pdf/1906.09551.pdf)
* 2019-Corbiere-Addressing Failure Prediction by learning model confidence [paper](https://arxiv.org/abs/1910.04851)
* 2019-Kumar-Verified Uncertainty Calibration [paper](https://papers.nips.cc/paper/8635-verified-uncertainty-calibration)
* 2020-Amersfoort-Uncertainty Estimation Using a Single Deep Deterministic Neural Network [paper](https://arxiv.org/abs/2003.02037)

* [paper](http://github.com)

## Ordinal Ranking
* 2017-Geifman-Selective Classification for Deep Neural Networks [paper](https://papers.nips.cc/paper/7073-selective-classification-for-deep-neural-networks.pdfm)
* 2018-Geifman-Bias-Reduced Uncertainty Estimation for Deep Neural Classifiers [paper](https://arxiv.org/abs/1805.08206)
* 2020-Moon-Confidence-Aware Learning for Deep Neural Networks [paper](https://arxiv.org/abs/2007.01458)
* [paper](http://github.com)

* * *
## Out of Distribution Dectection
* 2016-Hendrycks-A baseline for detecting misclassified and out-of-distribution examples in neural networks [paper](https://arxiv.org/abs/1610.02136)
* 2017-Lee-Training confidence-calibrated classifiers for detecting out-of-distribution samples [paper](https://arxiv.org/abs/1711.09325)
* 2017-Liang-Enhancing the reliability of out-of-distribution image detection in neural networks [paper](https://arxiv.org/abs/1706.02690)
* 2018-DeVries-Learning Confidence for Out-of-Distribution Detection in Neural Networks [paper](https://arxiv.org/abs/1802.04865)
* 2018-Hendrycks-Deep anomaly detection with outlier exposure [paper](https://arxiv.org/abs/1812.04606)
* 2018-Li-Reducing Over-confident Errors outside the Known Distribution [paper](https://arxiv.org/abs/1804.03166)
* 2019-Yu-Unsupervised Out-of-Distribution Detection by Maximum Classifier Discrepancy [paper](http://openaccess.thecvf.com/content_ICCV_2019/html/Yu_Unsupervised_Out-of-Distribution_Detection_by_Maximum_Classifier_Discrepancy_ICCV_2019_paper.html)
* 2019-Rohekar-Modeling Uncertainty by Learning a Hierarchy of Deep Neural Connections [paper](https://papers.nips.cc/paper/8677-modeling-uncertainty-by-learning-a-hierarchy-of-deep-neural-connections)
* 2019-Tagasovska-Single-Model Uncertainties for Deep Learning [paper](https://arxiv.org/abs/1811.00908)
* 2019-Roady-Are Out-of-Distribution Detection Methods Effective on Large-Scale Datasets?[paper](https://arxiv.org/pdf/1910.14034.pdf)
* 2020-Serr√†-Input complexity and out-of-distribution detection with likelihood-based generative models [paper](https://arxiv.org/abs/1909.11480)

* * *
## Adversarial Attack
* 2019-Andrew Ilyas-Adversarial Examples Are Not Bugs, They Are Features [paper](https://arxiv.org/abs/1905.02175) 
* 2020-Finlay-Confidence-Calibrated Adversarial Training: Generalizing to Unseen Attacks[paper](https://arxiv.org/abs/1903.09215)

* [paper](http://github.com)
